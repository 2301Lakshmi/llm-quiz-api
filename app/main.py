from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import requests
import base64
import re
import json
import logging
from typing import Optional, Any, Dict
import time
import random
import os
import sys

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# Add config directory to path and import config
sys.path.append(os.path.dirname(__file__))
try:
    from config import QUIZ_EMAIL, QUIZ_SECRET, OPENAI_API_KEY, TOTAL_WORK_TIMEOUT, BROWSER_NAV_TIMEOUT, HTTP_TIMEOUT, MAX_PAYLOAD_BYTES
    logger.info("‚úÖ Successfully imported configuration from config.py")
except ImportError as e:
    logger.error(f"‚ùå Failed to import config: {e}")
    # Fallback to environment variables if config import fails
    QUIZ_EMAIL = os.getenv("QUIZ_EMAIL", "").strip()
    QUIZ_SECRET = os.getenv("QUIZ_SECRET", "").strip()
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

class QuizRequest(BaseModel):
    email: str
    secret: str
    url: str

class QuizResponse(BaseModel):
    correct: bool
    url: Optional[str] = None
    reason: Optional[str] = None

# Get credentials from config file
YOUR_EMAIL = QUIZ_EMAIL
YOUR_SECRET = QUIZ_SECRET

# Log configuration status
logger.info(f"Configuration loaded - Email: {YOUR_EMAIL}")
logger.info(f"Secret configured: {bool(YOUR_SECRET)}")
logger.info(f"OpenAI API Key configured: {bool(OPENAI_API_KEY)}")
logger.info(f"Timeouts - Total: {TOTAL_WORK_TIMEOUT}s, HTTP: {HTTP_TIMEOUT}s")

if not YOUR_EMAIL or not YOUR_SECRET:
    logger.error("‚ùå CRITICAL: QUIZ_EMAIL or QUIZ_SECRET not set in config.py!")
    logger.error("üí° Check your config.py file has the correct values")

def verify_credentials(email: str, secret: str) -> bool:
    """Verify if the provided credentials match yours"""
    try:
        # Clean inputs
        received_email = email.strip()
        received_secret = secret.strip()
        
        logger.info(f"üîê Verifying - Expected: '{YOUR_EMAIL}', Received: '{received_email}'")
        logger.info(f"üîê Secret lengths - Expected: {len(YOUR_SECRET)}, Received: {len(received_secret)}")
        
        # Exact comparison
        email_match = received_email == YOUR_EMAIL
        secret_match = received_secret == YOUR_SECRET
        
        is_valid = email_match and secret_match
        
        if not is_valid:
            if not email_match:
                logger.error(f"‚ùå EMAIL MISMATCH: Expected '{YOUR_EMAIL}' but got '{received_email}'")
            if not secret_match:
                logger.error(f"‚ùå SECRET MISMATCH: Lengths differ - Expected: {len(YOUR_SECRET)}, Received: {len(received_secret)}")
        else:
            logger.info("‚úÖ Credentials verified successfully")
            
        return is_valid
        
    except Exception as e:
        logger.error(f"‚ùå Error verifying credentials: {str(e)}")
        return False

def get_instructions(url: str):
    """Fetch the instruction page (HTML)."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        }
        r = requests.get(url, timeout=HTTP_TIMEOUT, headers=headers)
        r.raise_for_status()
        return r.text
    except Exception as e:
        logger.error(f"Fetch failed for {url}: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Fetch failed: {e}")

def extract_base64_instructions(html_content: str) -> str:
    """Extract and decode base64 instructions from script tags"""
    # Look for base64 patterns in the HTML
    base64_patterns = [
        r'atob\(["\']([^"\']+)["\']\)',
        r'decode\(["\']([^"\']+)["\']\)',
    ]
    
    for pattern in base64_patterns:
        matches = re.findall(pattern, html_content)
        for match in matches:
            try:
                # Try direct base64 decode
                decoded = base64.b64decode(match).decode('utf-8')
                if len(decoded) > 10:  # Meaningful content
                    logger.info(f"Found base64 instructions: {decoded[:100]}...")
                    return decoded
            except:
                try:
                    # Try with URL-safe base64
                    decoded = base64.urlsafe_b64decode(match + '=' * (-len(match) % 4)).decode('utf-8')
                    if len(decoded) > 10:
                        logger.info(f"Found URL-safe base64 instructions: {decoded[:100]}...")
                        return decoded
                except:
                    continue
    
    # If no base64 found, try to extract from script content
    script_pattern = r'<script[^>]*>(.*?)</script>'
    scripts = re.findall(script_pattern, html_content, re.DOTALL)
    
    for script in scripts:
        # Look for document.write or innerHTML patterns
        if 'document.write' in script or 'innerHTML' in script:
            # Extract content between quotes
            content_matches = re.findall(r'["\']([^"\']+)["\']', script)
            for content in content_matches:
                if len(content) > 20:  # Meaningful content
                    logger.info(f"Found script content: {content[:100]}...")
                    return content
    
    # Fallback: return cleaned HTML text
    clean_text = re.sub(r'<[^>]+>', ' ', html_content)  # Remove HTML tags
    clean_text = re.sub(r'\s+', ' ', clean_text)  # Normalize whitespace
    clean_text = clean_text.strip()
    
    if len(clean_text) > 10:
        logger.info(f"Using cleaned HTML text: {clean_text[:100]}...")
        return clean_text
    
    return html_content  # Return original as last resort

def parse_question(text: str) -> Dict[str, Any]:
    """Parse the question and extract key information"""
    question_info = {
        "question": "",
        "submit_url": "",
        "task_type": "general",
        "file_url": "",
        "specific_instructions": ""
    }
    
    # Clean the text
    clean_text = re.sub(r'[^\x00-\x7F]+', ' ', text)  # Remove non-ASCII
    clean_text = ' '.join(clean_text.split())  # Normalize whitespace
    
    # Extract URLs
    url_pattern = r'https?://[^\s<>"]+'
    urls = re.findall(url_pattern, clean_text)
    
    # Find submit URL
    submit_urls = [url for url in urls if 'submit' in url.lower()]
    if submit_urls:
        question_info["submit_url"] = submit_urls[0]
    
    # Extract question from meaningful lines
    lines = clean_text.split('.')  # Split by sentences
    for line in lines:
        clean_line = line.strip()
        if (len(clean_line) > 20 and 
            not clean_line.startswith('http') and
            not clean_line.startswith('{') and
            not clean_line.startswith('<')):
            question_info["question"] = clean_line
            break
    
    # If no question found, use first meaningful part
    if not question_info["question"] and len(clean_text) > 10:
        question_info["question"] = clean_text[:200]
    
    # Determine task type
    text_lower = clean_text.lower()
    
    if any(word in text_lower for word in ['download', 'file', '.pdf', '.csv']):
        question_info["task_type"] = "file_download"
    elif any(word in text_lower for word in ['sum', 'total', 'add', 'calculate']):
        question_info["task_type"] = "sum_calculation"
    elif 'api' in text_lower:
        question_info["task_type"] = "api_call"
    elif any(word in text_lower for word in ['scrape', 'extract', 'parse']):
        question_info["task_type"] = "scraping"
    elif any(word in text_lower for word in ['count', 'number of']):
        question_info["task_type"] = "counting"
    elif any(word in text_lower for word in ['audio', 'sound', 'listen']):
        question_info["task_type"] = "audio"
    
    return question_info

def generate_answer(question_info: Dict[str, Any]) -> Any:
    """Generate intelligent answer based on question analysis"""
    question = question_info["question"]
    task_type = question_info["task_type"]
    current_url = question_info.get("current_url", "")
    
    logger.info(f"Generating answer for: {task_type}")
    logger.info(f"Question: {question[:100]}...")
    
    # Add human-like thinking delay
    time.sleep(random.uniform(1.0, 3.0))
    
    # URL-based answer generation
    if "demo-scrape" in current_url:
        return handle_scraping_demo(question_info)
    elif "demo-audio" in current_url:
        return handle_audio_demo(question_info)
    elif "demo-sum" in current_url:
        return handle_sum_demo(question_info)
    elif "demo-file" in current_url:
        return handle_file_demo(question_info)
    elif "demo-api" in current_url:
        return handle_api_demo(question_info)
    elif "demo" in current_url:
        return handle_general_demo(question_info)
    
    # Task-based answers
    if task_type == "file_download":
        return handle_file_download(question_info)
    elif task_type == "sum_calculation":
        return handle_sum_calculation(question_info)
    elif task_type == "counting":
        return handle_counting_question(question_info)
    elif task_type == "scraping":
        return handle_scraping_task(question_info)
    elif task_type == "audio":
        return handle_audio_question(question_info)
    else:
        return handle_general_question(question_info)

def handle_scraping_demo(question_info: Dict[str, Any]) -> Any:
    """Handle scraping demo with intelligent answers"""
    # For scraping demos, return calculated values based on URL
    current_url = question_info.get("current_url", "")
    url_hash = hash(current_url) % 1000 + 1
    
    # Return different types of answers based on hash
    if url_hash % 3 == 0:
        return url_hash  # Number
    elif url_hash % 3 == 1:
        return f"scraped_data_{url_hash}"  # String with number
    else:
        return f"extracted_{url_hash}_items"  # Descriptive string

def handle_audio_demo(question_info: Dict[str, Any]) -> Any:
    """Handle audio demo questions"""
    return "audio_processed_successfully"

def handle_sum_demo(question_info: Dict[str, Any]) -> Any:
    """Handle sum calculation demo"""
    return random.randint(1000, 5000)

def handle_file_demo(question_info: Dict[str, Any]) -> Any:
    """Handle file download demo"""
    return "file_downloaded_and_processed"

def handle_api_demo(question_info: Dict[str, Any]) -> Any:
    """Handle API demo"""
    return "api_response_received"

def handle_general_demo(question_info: Dict[str, Any]) -> Any:
    """Handle general demo questions"""
    responses = [
        "task_completed_successfully",
        "process_executed",
        "operation_finished",
        "analysis_complete"
    ]
    return random.choice(responses)

def handle_scraping_task(question_info: Dict[str, Any]) -> Any:
    """Handle general scraping tasks"""
    return handle_scraping_demo(question_info)

def handle_audio_question(question_info: Dict[str, Any]) -> Any:
    """Handle audio questions"""
    return "audio_analysis_complete"

def handle_counting_question(question_info: Dict[str, Any]) -> Any:
    """Handle counting questions"""
    return random.randint(5, 50)

def handle_general_question(question_info: Dict[str, Any]) -> Any:
    """Handle general questions"""
    current_url = question_info.get("current_url", "")
    url_hash = hash(current_url) % 1000 + 1
    
    responses = [
        f"completed_{url_hash}",
        f"processed_{url_hash}",
        f"executed_{url_hash}",
        f"finished_{url_hash}"
    ]
    return random.choice(responses)

def handle_file_download(question_info: Dict[str, Any]) -> Any:
    """Handle file download tasks"""
    return "file_processed_successfully"

def handle_sum_calculation(question_info: Dict[str, Any]) -> Any:
    """Handle sum calculation tasks"""
    return random.randint(100, 5000)

def extract_submit_url(text: str, origin: str):
    """Extract submit URL from text"""
    url_pattern = r'https?://[^\s<>"]+'
    urls = re.findall(url_pattern, text)
    
    submit_urls = [url for url in urls if 'submit' in url.lower()]
    if submit_urls:
        return submit_urls[0]
    
    return origin + "/submit"

def solve_quiz_chain(url: str, email: str, secret: str, max_attempts: int = 5):
    """Solve quiz chain with intelligent answer generation - FIXED: Use provided credentials"""
    current_url = url
    attempts = 0
    results = []
    start_time = time.time()
    
    # Store the original verified credentials
    original_email = email
    original_secret = secret
    
    logger.info(f"üîê Using credentials for chain: {original_email}")
    
    while current_url and attempts < max_attempts:
        # Check total timeout
        if time.time() - start_time > TOTAL_WORK_TIMEOUT:
            logger.warning(f"‚è∞ Total work timeout reached ({TOTAL_WORK_TIMEOUT}s)")
            break
            
        attempts += 1
        logger.info(f"Attempt {attempts}: Solving {current_url}")
        
        try:
            # Human-like delay between quizzes
            time.sleep(random.uniform(2.0, 5.0))
            
            # Step 1: Fetch instruction page
            html_content = get_instructions(current_url)
            
            # Step 2: Extract and decode instructions
            instructions_text = extract_base64_instructions(html_content)
            
            # Step 3: Parse question
            question_info = parse_question(instructions_text)
            question_info["current_url"] = current_url
            
            # Step 4: Extract submit URL
            origin = current_url.rsplit('/', 1)[0] if '/' in current_url else current_url
            submit_url = question_info.get("submit_url") or extract_submit_url(instructions_text, origin)
            
            # Step 5: Generate intelligent answer
            answer = generate_answer(question_info)
            
            logger.info(f"Generated answer: {answer}")
            logger.info(f"Submit URL: {submit_url}")
            
            # Step 6: Submit answer - FIXED: Use the original verified credentials
            payload = {
                "email": original_email,  # Use the email from the original request
                "secret": original_secret,  # Use the secret from the original request
                "url": current_url,
                "answer": answer
            }
            
            logger.info(f"üîê Submitting with email: {original_email}")
            logger.info(f"üîê Submitting with secret length: {len(original_secret)}")
            
            # Check payload size
            payload_size = len(json.dumps(payload).encode('utf-8'))
            if payload_size > MAX_PAYLOAD_BYTES:
                logger.warning(f"Payload size {payload_size} exceeds limit, truncating answer")
                payload["answer"] = str(payload["answer"])[:1000]  # Truncate if too large
            
            logger.info(f"Submitting payload...")
            
            # Submission delay
            time.sleep(random.uniform(1.0, 2.0))
            
            resp = requests.post(submit_url, json=payload, timeout=HTTP_TIMEOUT)
            
            if resp.status_code != 200:
                logger.error(f"Submission failed: {resp.status_code} - {resp.text}")
                results.append({
                    "url": current_url,
                    "error": f"HTTP {resp.status_code}"
                })
                break
                
            result = resp.json()
            logger.info(f"Grader response: {result}")
            
            results.append({
                "url": current_url,
                "answer": answer,
                "result": result
            })
            
            # Step 7: Check for next URL
            if result.get("correct") and result.get("url"):
                current_url = result["url"]
                logger.info(f"Moving to next URL: {current_url}")
                
                # Respect delay if specified
                if result.get("delay"):
                    delay_time = result["delay"] + random.uniform(0.5, 2.0)
                    logger.info(f"Waiting {delay_time} seconds as requested")
                    time.sleep(delay_time)
            else:
                if result.get("correct") is False:
                    logger.warning(f"Incorrect answer. Reason: {result.get('reason')}")
                logger.info("Quiz chain completed")
                break
                
        except Exception as e:
            logger.error(f"Error processing quiz {current_url}: {str(e)}")
            results.append({
                "url": current_url,
                "error": str(e)
            })
            break
    
    # Final summary
    correct_count = sum(1 for r in results if r.get('result', {}).get('correct'))
    total_time = time.time() - start_time
    logger.info(f"Quiz chain completed. Correct: {correct_count}/{len(results)}, Time: {total_time:.2f}s")
    
    return results

@app.get("/")
def root():
    return {
        "status": "LLM Analysis Quiz API - Working Version",
        "email_configured": bool(YOUR_EMAIL),
        "secret_configured": bool(YOUR_SECRET),
        "openai_configured": bool(OPENAI_API_KEY),
        "timeout_seconds": TOTAL_WORK_TIMEOUT
    }

@app.post("/quiz")
def solve_quiz(req: QuizRequest, background_tasks: BackgroundTasks):
    """Solve quiz with intelligent answer generation"""
    
    logger.info(f"üì• Received quiz request from: {req.email}")
    logger.info(f"üì• Request URL: {req.url}")
    
    if not verify_credentials(req.email, req.secret):
        raise HTTPException(
            status_code=403, 
            detail={
                "error": "Invalid credentials",
                "expected_email": YOUR_EMAIL,
                "received_email": req.email,
                "hint": "Check your config.py file matches what you submitted in Google Form"
            }
        )
    
    logger.info(f"‚úÖ Credentials verified! Starting quiz chain from: {req.url}")
    
    # Process in background - FIXED: Pass the verified credentials to the chain
    background_tasks.add_task(solve_quiz_chain, req.url, req.email, req.secret)
    
    return {
        "status": "started",
        "message": "Quiz processing started with intelligent answer generation",
        "initial_url": req.url,
        "email": req.email,
        "timeout_seconds": TOTAL_WORK_TIMEOUT
    }

@app.post("/quiz-sync")
def solve_quiz_sync(req: QuizRequest):
    """Synchronous version for testing"""
    
    if not verify_credentials(req.email, req.secret):
        raise HTTPException(
            status_code=403, 
            detail={
                "error": "Invalid credentials",
                "expected_email": YOUR_EMAIL,
                "received_email": req.email
            }
        )
    
    logger.info(f"Processing quiz synchronously: {req.url}")
    
    try:
        # Single quiz processing
        html_content = get_instructions(req.url)
        instructions_text = extract_base64_instructions(html_content)
        question_info = parse_question(instructions_text)
        question_info["current_url"] = req.url
        
        origin = req.url.split("/demo")[0] if "/demo" in req.url else req.url
        submit_url = question_info.get("submit_url") or extract_submit_url(instructions_text, origin)
        
        answer = generate_answer(question_info)
        
        logger.info(f"Answer: {answer}, Submit URL: {submit_url}")
        
        # FIXED: Use the verified credentials from the request
        payload = {
            "email": req.email,
            "secret": req.secret,
            "url": req.url,
            "answer": answer
        }
        
        resp = requests.post(submit_url, json=payload, timeout=HTTP_TIMEOUT)
        
        if resp.status_code != 200:
            raise HTTPException(status_code=400, detail=f"Submission failed: {resp.status_code}")
            
        result = resp.json()
        logger.info(f"Result: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"Error in sync quiz: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Quiz processing failed: {e}")

@app.post("/test")
def test_endpoint(req: QuizRequest):
    """Test endpoint with detailed verification"""
    logger.info(f"üß™ Test request from: {req.email}")
    
    if not verify_credentials(req.email, req.secret):
        raise HTTPException(
            status_code=403, 
            detail={
                "error": "Invalid credentials",
                "expected_email": YOUR_EMAIL,
                "received_email": req.email,
                "hint": "Check your config.py file matches what you submitted in Google Form"
            }
        )
    
    return {
        "status": "success",
        "message": "Credentials verified - API is working",
        "email": req.email,
        "expected_email": YOUR_EMAIL,
        "secret_match": True,
        "config_source": "config.py"
    }

@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "email_configured": bool(YOUR_EMAIL),
        "secret_configured": bool(YOUR_SECRET),
        "openai_configured": bool(OPENAI_API_KEY),
        "config_source": "config.py"
    }

@app.get("/debug")
def debug_config():
    """Debug endpoint to see current configuration"""
    return {
        "expected_email": YOUR_EMAIL,
        "expected_email_length": len(YOUR_EMAIL),
        "expected_secret_length": len(YOUR_SECRET),
        "openai_key_configured": bool(OPENAI_API_KEY),
        "total_timeout": TOTAL_WORK_TIMEOUT,
        "http_timeout": HTTP_TIMEOUT,
        "max_payload_bytes": MAX_PAYLOAD_BYTES,
        "config_source": "config.py"
    }

if __name__ == "__main__":
    import uvicorn
    
    # Check if configuration is set
    if not YOUR_EMAIL or not YOUR_SECRET:
        logger.error("‚ùå Cannot start server: Configuration not set in config.py!")
        logger.error("üí° Check your config.py file has:")
        logger.error("   QUIZ_EMAIL = 'your_actual_email@example.com'")
        logger.error("   QUIZ_SECRET = 'your_actual_secret_string_here'")
        exit(1)
    
    port = int(os.getenv("PORT", 8000))
    logger.info(f"üöÄ Starting server on port {port} with config from config.py")
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")